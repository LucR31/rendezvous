{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7974478a-de9d-4602-8047-1a3b8decb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging.config\n",
    "import math\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d29cec-ee4c-40ce-b196-7fe75cb0e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "from poliastro.bodies import Earth\n",
    "from poliastro.twobody import Orbit\n",
    "from poliastro.plotting import OrbitPlotter2D\n",
    "from poliastro.maneuver import Maneuver\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "873696f9-a7fc-4a89-a746-c8afebe1d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Goal spaceship data\"\"\"\n",
    "r = [-6045, -3490, 2500] << u.km\n",
    "v = [-3.457, 6.618, 2.533] << u.km / u.s\n",
    "nostromo = Orbit.from_vectors(Earth, r, v)\n",
    "\n",
    "class Poliastro_env(gym.Env):\n",
    "    \n",
    "\n",
    "    def __init__(self,r_1= [-6045, -3490, 2500]<< u.km,\n",
    "                      v_1= [-3.457, 6.618, 2.533]<< u.km/u.s):\n",
    "        \n",
    "        # Initial orbit\n",
    "        self.r_1 = r_1\n",
    "        self.v_1 = v_1\n",
    "        self.orbit = Orbit.from_vectors(Earth, r_1, v_1)\n",
    "        \n",
    "        #Action space \n",
    "        self.action_space = spaces.Box(low=np.array([-5, -5, -5]),\n",
    "                                       high=np.array([5,5,5]),\n",
    "                                       dtype=np.float16)\n",
    "        \n",
    "        #observation space\n",
    "        self.observation_space = spaces.Box(low=-10000, high=10000, shape=(1,1,1),\n",
    "                                       dtype=np.float16)\n",
    "        \n",
    "    def _get_obs(self):\n",
    "        \n",
    "        return {\"agent\": self.orbit.r.value, \"target\": nostromo.r.value}\n",
    "    \n",
    "    def step(self,action):\n",
    "           \n",
    "        \"\"\"Take the action and make time pass\"\"\"\n",
    "        dv = action << (u.m / u.s)\n",
    "        self.orbit = self.orbit.apply_maneuver(Maneuver.impulse(dv))\n",
    "        self.orbit=self.orbit.propagate(10<<u.min)\n",
    "        \n",
    "        \"\"\"Get reward \"\"\"\n",
    "        reward=self.get_reward()\n",
    "        \n",
    "        \"\"\"Get observation\"\"\"\n",
    "        observation = self._get_obs()\n",
    "        \n",
    "        \"\"\"If crash, end the task\"\"\"\n",
    "        done=True if self.ground_check() or self.too_far() or reward>=10 else False\n",
    "         \n",
    "        return reward, done, observation\n",
    "    \n",
    "    def get_reward(self):\n",
    "        \n",
    "        dist=self.check_distance()\n",
    "        \n",
    "        if dist<100:\n",
    "            return int(100-dist)\n",
    "        return 0\n",
    "              \n",
    "    def ground_check(self): \n",
    "        \n",
    "        perigee=self.orbit.a*(1-self.orbit.ecc) \n",
    "    \n",
    "        if perigee <= 6371<< u.km:\n",
    "            return True    \n",
    "        return False\n",
    "    \n",
    "    def too_far(self):\n",
    "        \n",
    "        return True if self.orbit.a>16000<< u.km else False\n",
    "    \n",
    "    def check_distance(self):\n",
    "        \n",
    "        \"\"\" Get the difference between both orbits\n",
    "        need a formula for it\"\"\"\n",
    "        \n",
    "        a=self.orbit.a.value\n",
    "        b=nostromo.a.value\n",
    "        e=self.orbit.ecc.value\n",
    "        d=nostromo.ecc.value\n",
    "        \n",
    "        diff=0\n",
    "        for x in np.linspace(0, 6, 20):\n",
    "            r_1=a*(1-e**2)/(1+e*np.cos(x))\n",
    "            r_2=b*(1-d**2)/(1+d*np.cos(x))\n",
    "            diff+=abs(r_1-r_2)\n",
    "           \n",
    "        return diff\n",
    "\n",
    "    def reset(self):\n",
    "        self.orbit=Orbit.from_vectors(Earth, self.r_1, self.v_1)\n",
    "        return None\n",
    "\n",
    "    def render(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d3288-5ce1-4869-b812-66af0abdb715",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Env Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c7d548-2365-4802-b631-716c22a33833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rl/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float16\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env=Poliastro_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b88f87-f851-4d89-aa4b-191eaad64a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent': array([-6045., -3490.,  2500.]),\n",
       " 'target': array([-6045., -3490.,  2500.])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env._get_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd7481a4-ae54-454e-adee-a5a00179786d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1  Score:22%  Steps: 3166\n",
      "Episode:2  Score:67%  Steps: 2\n",
      "Episode:3  Score:64%  Steps: 3\n",
      "Episode:4  Score:31%  Steps: 84\n",
      "Episode:5  Score:58%  Steps: 1\n",
      "Episode:6  Score:73%  Steps: 1\n",
      "Episode:7  Score:0%  Steps: 12001\n",
      "Episode:8  Score:66%  Steps: 1\n",
      "Episode:9  Score:48%  Steps: 2\n",
      "Episode:10  Score:69%  Steps: 162\n",
      "Episode:11  Score:14%  Steps: 1\n",
      "Episode:12  Score:22%  Steps: 260\n",
      "Episode:13  Score:0%  Steps: 12001\n",
      "Episode:14  Score:29%  Steps: 329\n",
      "Episode:15  Score:34%  Steps: 1\n",
      "Episode:16  Score:0%  Steps: 12001\n",
      "Episode:17  Score:11%  Steps: 46\n",
      "Episode:18  Score:60%  Steps: 1\n",
      "Episode:19  Score:21%  Steps: 831\n",
      "Episode:20  Score:76%  Steps: 1\n",
      "Episode:21  Score:87%  Steps: 2\n",
      "Episode:22  Score:40%  Steps: 1068\n",
      "Episode:23  Score:43%  Steps: 534\n",
      "Episode:24  Score:12%  Steps: 2\n",
      "Episode:25  Score:12%  Steps: 4\n",
      "Episode:26  Score:0%  Steps: 12001\n",
      "Episode:27  Score:17%  Steps: 1\n",
      "Episode:28  Score:64%  Steps: 1\n",
      "Episode:29  Score:89%  Steps: 2\n",
      "Episode:30  Score:13%  Steps: 2\n",
      "Episode:31  Score:28%  Steps: 62\n",
      "Episode:32  Score:0%  Steps: 7056\n",
      "Episode:33  Score:12%  Steps: 1\n",
      "Episode:34  Score:0%  Steps: 6468\n",
      "Episode:35  Score:38%  Steps: 11\n",
      "Episode:36  Score:81%  Steps: 2\n",
      "Episode:37  Score:0%  Steps: 9598\n",
      "Episode:38  Score:57%  Steps: 1\n",
      "Episode:39  Score:11%  Steps: 1017\n",
      "Episode:40  Score:44%  Steps: 1\n",
      "Episode:41  Score:66%  Steps: 6\n",
      "Episode:42  Score:85%  Steps: 1\n",
      "Episode:43  Score:60%  Steps: 1\n",
      "Episode:44  Score:60%  Steps: 1\n",
      "Episode:45  Score:0%  Steps: 12001\n",
      "Episode:46  Score:54%  Steps: 16\n",
      "Episode:47  Score:0%  Steps: 12001\n",
      "Episode:48  Score:54%  Steps: 2\n",
      "Episode:49  Score:43%  Steps: 1\n",
      "Episode:50  Score:8%  Steps: 6212\n"
     ]
    }
   ],
   "source": [
    "episodes=50\n",
    "\n",
    "for episode in range(1,episodes+1):\n",
    "    \n",
    "    env.reset()\n",
    "    done=False\n",
    "    score=0\n",
    "    steps=0\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        #env.render()\n",
    "        action=env.action_space.sample()\n",
    "        reward, done, observation = env.step(action)\n",
    "        score+=reward\n",
    "        steps+=1\n",
    "        if steps>12000:\n",
    "            break\n",
    "        \n",
    "    print(\"Episode:{}  Score:{}%  Steps: {}\".format(episode, score, steps))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
